---
title: 数据处理
categories: 
- ElasticSearch实战
---

Document最终存储到分片上，那么文档的数据是如何选择要存储的分片的呢？

* 此时，就需要**「文档到分片的映射算法」**。

目的：是文档均匀分布到所有分片上，以充分利用资源。之所以不用随机和轮询round-robin算法的原因是：

> 需要维护文档到分片的映射关系，那么在PB级别的数据量的时候，这是一个成本非常大的工程。 

所以：**「直接根据文档值实时计算对应的分片即可」**。

分片的计算公式：

```java
shard = hash(routing)%number_of_primary_shards 
```

hash保证数据均匀分布在分片中，routing作为关键参数，默认为文档ID，`number_of_primary_shards`为主分片数。 

这也是为什么，主分片数一旦设定，不能更改的原因————**「为了保证文档对应的分片不会发生改变」**。

**写数据**

* 客户端选择一个 node 发送请求，这个node 就是 coordinating node（协调节点）

* coordinating node 对 doc 进行路由，将请求转发给对应的node（有primary shard）

* 实际的 node 上的 primary shard 处理请求，然后将数据同步到 replica node

* coordinating node 如果发现 primary node 和所有 replica node 都搞定之后，就返回响应结果给客户端

**搜索数据**

* 客户端发送请求到一个 coordinate node

* 协调节点将搜索请求转发到该索引所有的 shard 对应的 primary shard或 replica shard 上

**query phase：**

* 每个 shard 将自己的搜索结果（一些 doc id ）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果

**fetch phase（读数据过程）：**

* 接着由协调节点根据 doc id 去各个节点上拉取实际的 doc 数据，最终返回给客户端

* 写请求是写入 primary shard，然后同步给所有的 replica shard；
* 读请求可以从 primary shard 或 replica shard 读取，采用的是随机轮询算法

**读数据**

* 可以通过 doc id 来查询，会根据 doc id 进行 hash，判断出来当时把 doc id 分配到了哪个 shard 上面去，从那个 shard 去查询

* 客户端发送请求到任意一个 node，成为 coordinate node

* coordinate node 对 doc id 进行哈希路由，将请求转发到对应的 node，此时会使用 round-robin 随机轮训算法，在 primary shard 以及其所有 replica shard 中随机选择一个，让读请求负载均衡

* 接收请求的 node 返回 doc 给 coordinate node ，coordinate node 返回 doc 给客户端