---
title: 集群
categories: 
- ElasticSearch实战
---

ES支持集群模式，即一个分布式系统。

其好处主要有以下2个：

* 可增大系统容量。比如：内存、磁盘的增加使得ES能够支持PB级别的数据；

* 提高了系统可用性。即使一部分节点停止服务，集群依然可以正常对外服务。

ES集群由多个ES实例构成：

* 不同集群通过集群名字来区分，通过配置文件`elasticsearch.yml`中的`cluster.name`可以修改，默认为elasticsearch。
* 每个ES实例的本质，其实是一个JVM进程，且有自己的名字，通过配置文件中的`node.name`可以修改。

**几个节点：**

* **「主节点master」**：可修改cluster state的节点。一个集群仅一个。 cluster state存储于每个节点上，master维护最新版本并向其他从节点同步。

* **「选举节点master-eligible」**：可以参与选举master的节点。 配置为：`node.master:true`。默认所有节点都可以参与选举。

* **「协调节点cordinating」**：处理请求的节点。是所有节点的默认角色，且不能取消。 路由请求到正确的节点处理，如：创建索引的请求到master节点。

* **「从节点data」**：存储数据的节点，默认所有节点都是data类型。 配置为：`node.data:true`。

**集群健康状态**

* Greed，绿色。表示所有主分片和副本分片都正常分配；

* Yellow，黄色。表示所有主分片都正常分配，但有副本分片未分配；

* Red，红色。表示有主分片未分配。

**分片**

分片是ES能支持PB级别数据的基石。

* 分片存储部分数据，可以分布于任意节点；
* 分片数在索引创建时指定，且后续不能更改，默认为5个；
* 有主分片和副本分片之分，以实现数据的高可用；
* 副本分片由主分片同步数据，可以有多个，从而提高数据吞吐量。

# 脑裂问题

**产生脑裂问题的原因**

> 1.网络

由于某些节点之间的网络通信出现问题，导致一些节点认为master节点已经挂了，所以有重新选举了新的master节点，从而导致集群信息混乱

> 2.节点负载过大

由于master节点与data节点都是混在一起的，有可能master节点的负载过大，导致对应的es实例停止响应，这时一部分节点会一位master节点已经挂掉从而重新选举，导致多master节点运行。

同时由于data节点上ES进程占用的内存较大，较大规模的内存回收操作也能造成ES进程失去响应

> 这个原因的可能性应该是最大的

**发现脑裂问题**

Elasticsearch出现查询非常缓慢的情况

通过命令查看集群的状态

```java
curl -XGET ‘http://localhost:9200/_cluster/health’
```

发现集群状态为red，且集群数量明显错误，再向不同的节点查询集群状态的时候，总体状态都是red，但是返回的集群数量却不太一样

正常情况下，访问每一个节点，对集群中的状态返回应该是一致的，不一致的信息表示集群中不同节点对master节点的选择出现了问题。导致集群不能正常工作

**如何解决脑裂问题**

对于网络问题，只能进行网络修复，在重启集群

> 对于负载的问题

一个直观的解决方案就是将master节点与data节点分离，准备几台机器加入集群中，这几台机器只能充当master节点，不可担任存储和搜索的角色

```java
其他节点只能充当data不能充当master
node.master: false
node.data: true
```

**还有两个参数的修改可以减少脑裂问题的出现**

> discovery.zen.ping_timeout（默认值是3秒）

默认情况下，一个节点会认为，如果master节点在3秒之内没有应答，那么这个节点就是死掉了，而增加这个值，会增加节点等待响应的时间，从一定程度上会减少误判

> discovery.zen.minimum_master_nodes（默认是1）

这个参数控制的是，一个节点需要看到的具有master节点资格的最小数量，然后才能在集群中做操作。

官方的推荐值是(N/2)+1，其中N是具有master资格的节点的数量

master主节点应该要经过多个有资格成为master（`node.master=true`）的节点选举后才能成为新的节点，不是一个人自己选自己就能决定

在ES7.x版本中，这个参数已经被移除了，这块的内容完全由ES自身做管理，避免了多个脑裂的情况，选举也非常快