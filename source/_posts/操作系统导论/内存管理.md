---
title: 内存管理
categories: 
- 操作系统导论
---

**逻辑地址和物理地址**

我们编程一般只有可能和逻辑地址打交道，比如在 C 语言中，指针里面存储的数值就可以理解成为内存里的一个地址，这个地址也就是我们说的逻辑地址，逻辑地址由操作系统决定。

物理地址指的是真实物理内存中地址，更具体一点来说就是内存地址寄存器中的地址，物理地址是内存单元真正的地址。

编译时只需确定变量x存放的相对地址是100 ( 也就是说相对于进程在内存中的起始地址而言的地址)。

CPU想要找到x在内存中的实际存放位置，只需要用进程的起始地址+100即可。 

相对地址又称逻辑地址，绝对地址又称物理地址。

**内存管理有哪几种方式**

1. **块式管理**：将内存分为几个固定大小的块，每个块中只包含一个进程，如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了，这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理**：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片，页式管理通过页表对应逻辑地址和物理地址。

<img src="https://img-blog.csdnimg.cn/a9ac3bf5e08e49ff9ed731ae54424132.png" style="zoom:25%;" />

1. **段式管理**： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义， 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 ，段式管理通过段表对应逻辑地址和物理地址。
2. **段页式管理机制：**段页式管理机制结合了段式管理和页式管理的优点，简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说**段页式管理机制**中段与段之间以及段的内部的都是离散的。

<img src="https://img-blog.csdnimg.cn/92a8f2f5def248648db8392d96247400.png" style="zoom:25%;" />

# 虚拟地址

现代处理器使用的是一种称为**虚拟寻址(Virtual Addressing)**的寻址方式

**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。**

实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为**内存管理单元（Memory Management Unit, MMU）**的硬件

<img src="https://img-blog.csdnimg.cn/0ef33a73d3974272909d641634703314.png" style="zoom:50%;" />

**为什么要有虚拟地址空间**

没有虚拟地址空间的时候，**程序都是直接访问和操作的都是物理内存**。

但是这样有什么问题？

1. 用户程序可以访问任意内存，寻址内存的每个字节，这样就很容易破坏操作系统，造成操作系统崩溃。
2. 想要同时运行多个程序特别困难，比如你想同时运行一个微信和一个 QQ 音乐都不行，为什么呢？举个简单的例子：微信在运行的时候给内存地址 1xxx 赋值后，QQ 音乐也同样给内存地址 1xxx 赋值，那么 QQ 音乐对内存的赋值就会覆盖微信之前所赋的值，这就造成了微信这个程序就会崩溃。

**通过虚拟地址访问内存有以下优势：**

- 程序可以使用一系列相邻的虚拟地址来访问物理内存中不相邻的大内存缓冲区。
- 程序可以使用一系列虚拟地址来访问大于可用物理内存的内存缓冲区。
- 不同进程使用的虚拟地址彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。

**MMU如何把虚拟地址翻译成物理地址的**

对于每个程序，内存管理单元MMU都为其保存一个页表，该页表中存放的是虚拟页面到物理页面的映射。

每当为一个虚拟页面寻找到一个物理页面之后，就在页表里增加一条记录来保留该映射关系，当然，随着虚拟页面进出物理内存，页表的内容也会不断更新变化。

<img src="https://img-blog.csdnimg.cn/f967e12729bd470eaf9d32221209ba36.png" style="zoom:25%;" />

# 虚拟内存

很多时候我们使用点开了很多占内存的软件，这些软件占用的内存可能已经远远超出了我们电脑本身具有的物理内存

通过 **虚拟内存** 可以让程序可以拥有超过系统物理内存大小的可用内存空间。

另外，虚拟内存为每个进程提供了一个一致的、私有的地址空间，它让每个进程产生了一种自己在独享主存的错觉（每个进程拥有一片连续完整的内存空间），这样会更加有效地管理内存并减少出错。

**虚拟内存**是计算机系统内存管理的一种技术，我们可以手动设置自己电脑的虚拟内存

**虚拟内存的重要意义是它定义了一个连续的虚拟地址空间**，并且 **把内存扩展到硬盘空间**

**虚拟内存的实现有以下三种方式：**

1. **请求分页存储管理** ：请求分页是目前最常用的一种实现虚拟存储器的方法，请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分段即可运行，假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

不管是上面那种实现方式，我们一般都需要：

> 一定容量的内存和外存：在载入程序的时候，只需要将程序的一部分装入内存，而将其他部分留在外存，然后程序就可以执行了；

<img src="https://img-blog.csdnimg.cn/87aa376bd74a4561962682ecab2c0d43.png" style="zoom:25%;" />



# 缺页中断

如果**需执行的指令或访问的数据尚未在内存**（称为缺页或缺段），则由处理器通知操作系统将相应的页面或段**调入到内存**，然后继续执行程序；

在分页系统中，一个虚拟页面既有可能在物理内存，也有可能保存在磁盘上。

如果CPU发出的虚拟地址对应的页面不在物理内存，就将产生一个缺页中断，而缺页中断服务程序负责将需要的虚拟页面找到并加载到内存。

缺页中断的处理步骤如下，省略了中间很多的步骤，只保留最核心的几个步骤：

<img src="https://img-blog.csdnimg.cn/0985097c9d61404a83711157b897cb5a.png" style="zoom:50%;" />

# 页面置换算法

当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。

用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则

- **OPT 页面置换算法（最佳页面置换算法）** ：该置换算法所选择的被淘汰页面将是以后永不使用的，或者是在最长时间内不再被访问的页面，这样可以保证获得最低的缺页率，但由于人们目前无法预知进程在内存下的若千页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现，一般作为衡量其他置换算法的方法。
- **FIFO（First In First Out） 页面置换算法（先进先出页面置换算法）** : 总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。

- **LRU （Least Currently Used）页面置换算法（最近最久未使用页面置换算法）** ：LRU算法赋予每个页面一个访问字段，用来记录一个页面自上次被访问以来所经历的时间 T，当须淘汰一个页面时，选择现有页面中其 T 值最大的，即最近最久未使用的页面予以淘汰。
- **LFU （Least Frequently Used）页面置换算法（最少使用页面置换算法）** : 该置换算法选择在之前时期使用最少的页面作为淘汰页。

# 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问，产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到**高速缓存存储器**中，并使用高速缓存的层次结构实现。

空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。

# 页表

操作系统将虚拟内存分块，每个小块称为一个页（Page）；真实内存也需要分块，每个小块我们称为一个 Frame。

Page 到 Frame 的映射，需要一种叫作页表的结构。

<img src="https://img-blog.csdnimg.cn/a15bed2353c74a62975e451eac3aff00.png" style="zoom:25%;" />

上图展示了 Page、Frame 和页表 （PageTable）三者之间的关系。 

Page 大小和 Frame 大小通常相等，页表中记录的某个 Page 对应的 Frame 编号。

页表也需要存储空间，比如虚拟内存大小为 10G， Page 大小是 4K，那么需要 10G/4K = 2621440 个条目。

如果每个条目是 64bit，那么一共需要 20480K = 20M 页表，操作系统在内存中划分出小块区域给页表，并负责维护页表。

**页表维护了虚拟地址到真实地址的映射。**

每次程序使用内存时，需要把虚拟内存地址换算成物理内存地址，换算过程分为以下 3 个步骤：

* 通过虚拟地址计算 Page 编号；

* 查页表，根据 Page 编号，找到 Frame 编号；

* 将虚拟地址换算成物理地址。

## 多级页表

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中

**一级页表：**

假如物理内存中一共有1048576个页，那么页表就需要总共就是`1048576 * 4B = 4M`。

也就是说我需要4M连续的内存来存放这个页表，也就是一级页表。

随着虚拟地址空间的增大，存放页表所需要的连续空间也会增大，在操作系统内存紧张或者内存碎片较多时，这无疑会带来额外的开销。

页表寻址是用寄存器来确定一级页表地址的，所以一级页表的地址必须指向确定的物理页，否则就会出现错误，所以如果用一级页表的话，就必须把全部的页表都加载进去。

**二级页表：**

而使用二级页表的话，只需要加载一个页目录表(一级页表)，大小为4K，可以管理1024个二级页表。

可能你会有疑问，这1024个二级页表也是需要内存空间的，这下反而需要4MB+4KB的内存，反而更多了。

其实二级页表并不是一定要存在内存中的，内存中只需要一个一级页表地址存在存器即可，二级页表可以使用缺页中断从外存移入内存。

**多级页表属于时间换空间的典型场景**

# 快表

为了解决虚拟地址到物理地址的转换速度，操作系统在**页表方案**基础之上引入了**快表**来加速虚拟地址到物理地址的转换

我们可以把快表理解为一种特殊的**高速缓冲存储器（Cache）**，其中的内容是页表的一部分或者全部内容，作为页表的 Cache，它的作用与页表相似，但是提高了访问速率，由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存，有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

**使用快表之后的地址转换流程是这样的：**

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理地址；
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

<img src="https://img-blog.csdnimg.cn/de56049e24c44756911ceded6d703d53.png" style="zoom:25%;" />

# 内存管理单元

在 CPU 中一个小型的设备——内存管理单元（MMU）

<img src="https://img-blog.csdnimg.cn/2da3a2f130cf415cb0b42c19fda70f30.png" style="zoom:25%;" />

<img src="https://img-blog.csdnimg.cn/5bddbadd99e244c185886d4cd9ab239f.png" style="zoom:25%;" />

当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后，MMU 连接了地址总线，帮助 CPU 操作真实地址。

在不同 CPU 的 MMU 可能是不同的，因此这里会遇到很多跨平台的问题。

解决跨平台问题不但有繁重的工作量，更需要高超的编程技巧。

# 动态分区分配算法

内存分配算法，大体来说分为：**连续式分配 与 非连续式分配**

连续式分配就是把所以要执行的程序 **完整的，有序的** 存入内存，连续式分配又可以分为**固定分区分配 和 动态分区分配**

非连续式分配就是把要执行的程序按照一定规则进行拆分，显然这样更有效率，现在的操作系统通常也都是采用这种方式分配内存

所谓动态分区分配，就是指**内存在初始时不会划分区域，而是会在进程装入时，根据所要装入的进程大小动态地对内存空间进行划分，以提高内存空间利用率，降低碎片的大小**

动态分区分配算法有以下四种：

> 首次适应算法（First Fit）

空闲分区以地址递增的次序链接，分配内存时顺序查找，找到大小满足要求的第一个空闲分区就进行分配

<img src="https://img-blog.csdnimg.cn/e5cf8456bf9941758f6a1bd2ba1c351a.png" style="zoom:25%;" />

> 邻近适应算法（Next Fit）

又称循环首次适应法，由首次适应法演变而成，不同之处是分配内存时从上一次查找结束的位置开始继续查找

<img src="https://img-blog.csdnimg.cn/563c30ab6fdf4f209f8efa7654bfe1a3.png" style="zoom:25%;" />

> 最佳适应算法（Best Fit）

空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区就进行分配

<img src="https://img-blog.csdnimg.cn/585a5ba3e4ad4eaeae77ebd1d8b02b32.png" style="zoom:25%;" />

> 最坏适应算法（Next Fit）

又称最大适应算法，空闲分区以容量递减的次序链接，找到第一个能满足要求的空闲分区（也就是最大的分区）就进行分配

<img src="https://img-blog.csdnimg.cn/5379ed3464c945bcaf46dbf5f02bfbea.png" style="zoom:25%;" />

**总结**

首次适应不仅最简单，通常也是最好最快，不过首次适应算法会使得内存低地址部分出现很多小的空闲分区，而每次查找都要经过这些分区，因此也增加了查找的开销。

邻近算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间分裂成小的碎片，它通常比首次适应算法结果要差。

最佳适应算法导致大量碎片，最坏适应算法导致没有大的空间。

# 内存覆盖

覆盖与交换技术是在程序用来扩充内存的两种方法。

早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程的现象也经常发生，这一矛盾可以用覆盖技术来解决。

**覆盖的基本思想是：**

由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），因此可以把用户空间分成一个固定区和若干个覆盖区。

将经常活跃的部分放在固定区，其余部分按调用关系分段。

首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调入覆盖区，替换覆盖区中原有的段。

覆盖技术的特点是打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的代码量大于主存时仍不能运行。

# 内存交换

**交换的基本思想**

把处于等待状态（或在CPU调度原则下被剥夺运行权利）的程序从内存移到辅存，把内存空间腾出来，这一过程又叫换出；

把准备好竞争CPU运行的程序从辅存移到内存，这一过程又称为换入。

> 例如，有一个CPU釆用时间片轮转调度算法的多道程序环境。

时间片到，内存管理器将刚刚执行过的进程换出，将另一进程换入到刚刚释放的内存空间中。

同时，CPU调度器可以将时间片分配给其他已在内存中的进程。

每个进程用完时间片都与另一进程交换。

理想情况下，内存管理器的交换过程速度足够快，总有进程在内存中可以执行。

> 交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。

由于覆盖技术要求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛盾

现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统中仍具有较强的生命力。