---
title: 数据持久化
categories: 
- 中间件
- Elasticsearch
---

Elasticsearch底层采用的是lucene这个库来实现倒排索引的功能，在lucene里每一条记录称为document(文档)，lucene使用segment(分段)来存储数据，用commit point来记录所有segment的元数据，一条记录要被搜索到，必须写入到segment中。

<img src="https://img-blog.csdnimg.cn/5ce5035dff664ce49782473bd5a51ecb.png" alt="img" style="zoom:25%;" />

<img src="https://img-blog.csdnimg.cn/c15e1f86f0834c738c83b342f28a38ab.png" alt="img" style="zoom:25%;" />

**整体流程：**

数据首先写入内存缓存区和Translog日志文件中，当你写一条数据doc的时候，一方面写入到内存缓冲区中，一方面同时写入到Translog日志文件中。

内存缓存区满了或者每隔1秒(默认1秒)，refresh将内存缓存区的数据生成index segment文件并写入文件系统缓存区，此时index segment可被打开以供search查询读取，这样文档就可以被搜索到了（**此时文档还没有写到磁盘上**），然后清空内存缓存区供后续使用。

可见，refresh实现的是文档从内存缓存区移到文件系统缓存区的过程。

重复上两个步骤，新的segment不断添加到文件系统缓存区，内存缓存区不断被清空，而translog的数据不断增加，随着时间的推移，Translog文件会越来越大。

当Translog长度达到一定程度的时候，会触发flush操作，否则默认每隔30分钟也会定时flush。

**删除和更新**

由于 segment 是不可变的，索引删除的时候既不能把文档从 segment 删除，也不能修改 segment 反映文档的更新

- 删除操作，会生成一个 `.del` 文件，commit point 会包含这个 `.del` 文件，`.del` 文件将文档标识为 deleted 状态，在结果返回前从结果集中删除。

- 更新操作，会将原来的文档标识为 deleted 状态，然后新写入一条数据，查询时两个文档有可能都被索引到，但是被标记为删除的文档会被从结果集删除

**segment合并**

内存缓存区 每 refresh 一次，就会产生一个 segment（默认情况下是 1 秒钟产生一个），这样 segment 会越来越多，此时会定期执行 merge

-  将多个 segment 合并成一个，并将新的 segment 写入磁盘 

-  新增一个 commit point，标识所有新的 segment 

-  新的 segment 被打开供搜索使用 

-  删除旧的 segment 