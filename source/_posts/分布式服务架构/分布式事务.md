---
title: 分布式事务
categories: 
- 分布式服务架构
---

**典型场景**

> 跨库事务

跨库事务指的是，一个应用某个功能需要操作多个库，不同的库中存储不同的业务数据。

> 分库分表

通常一个库数据量比较大或者预期未来的数据量比较大，都会进行水平拆分，也就是分库分表

> 服务化(SOA)

Service A完成某个功能需要直接操作数据库，同时需要调用Service B和Service C，而Service B又同时操作了2个数据库，Service C也操作了一个库。

需要保证这些跨服务的对多个数据库的操作要不都成功，要不都失败，实际上这可能是最典型的分布式事务场景。

# 最大努力通知

最大努力通知型是最简单的一种柔性事务，适用于一些最终一致性时间敏感度低的业务，且被动方处理结果 不影响主动方的处理结果。

典型的使用场景：如银行通知、商户通知等。

最大努力通知型的实现方案，一般符合以下特点：

* 不可靠消息：业务活动主动方，在完成业务处理之后，向业务活动的被动方发送消息，直到通知N次后不再通知，允许消息丢失(不可靠消息)。

* 定期校对：业务活动的被动方，根据定时策略，向业务活动主动方查询(主动方提供查询接口)，恢复丢失的业务消息。

**举例来说：**

一个短信发送平台，背景是公司内部有多个业务都有发送短信的需求，如果每个业务独立实现短信发送功能，存在功能实现上的重复。

因此专门做了一个短信平台项目，所有的业务方都接入这个短信平台，来实现发送短信的功能

<img src="https://img-blog.csdnimg.cn/1360162650274086a7c02377406251cb.png" style="zoom:50%;" />

**短信发送流程如下：**

* 业务方将短信发送请求提交给短信平台
* 短信平台接收到要发送的短信，记录到数据库中，并标记其状态为已接收
* 短信平台调用外部短信发送供应商的接口，发送短信。外部供应商的接口也是异步将短信发送到用户手机上，因此这个接口调用后，立即返回，进入第4步。
* 更新短信发送状态为已发送
* 短信发送供应商异步通知短信平台短信发送结果。而通知可能失败，因此最多只会通知N次。
* 短信平台接收到短信发送结果后，更新短信发送状态，可能是成功，也可能失败(如手机欠费)。到底是成功还是失败并不重要，重要的是我们知道了这调短信发送的最终结果
* 如果最多只通知N次，如果都失败了的话，那么短信平台将不知道短信到底有没有成功发送。因此短信发送供应商需要提供一个查询接口，以方便短信平台驱动的去查询，进行定期校对。

在这个案例中，短信发送供应商通知短信平台短信发送结果的过程中，就是最典型的最大努力通知型方案，通知了N次就不再通知。

通过提供一个短信结果查询接口，让短信平台可以进行定期的校对。而由于短信发送业务的时间敏感度并不高，比较适合采用这个方案。

需要注意的是，短信结果查询接口很重要，必须要进行定期校对。因为后期要进行对账，笔者在做这个项目的时候，一个月的短信发送总量在高峰期可以达到1亿条左右，即使一条短信只要5分钱，一个月就有500W。

# 消息最终一致性

**消息发送一致性：**

是指产生消息的业务动作与消息发送的一致。

也就是说，如果业务操作成功，那么由这个业务操作所产生的消息一定要成功投递出去(一般是发送到kafka、rocketmq、rabbitmq等消息中间件中)，否则就丢消息。

**基于MQ的事务消息，以下展示了RocketMQ的事务消息机制**

<img src="https://img-blog.csdnimg.cn/6e0c3d782ef04c4388cf830b8f54e814.png" style="zoom:50%;" />

事务消息的逻辑，由发送端 Producer进行保证(消费端无需考虑)

首先，发送一个事务消息，这个时候，RocketMQ将消息状态标记为Prepared，注意此时这条消息消费者是无法消费到的。

接着，执行业务代码逻辑，可能是一个本地数据库事务操作

最后，确认发送消息，这个时候，RocketMQ将消息状态标记为可消费，这个时候消费者，才能真正的保证消费到这条数据。

**如果确认消息发送失败了怎么办？**

RocketMQ会定期扫描消息集群中的事务消息，如果发现了Prepared消息，它会向消息发送端(生产者)确认。

RocketMQ会根据发送端设置的策略来决定是回滚还是继续发送确认消息。这样就保证了消息发送与本地事务同时成功或同时失败。

如果消费失败怎么办？阿里提供给我们的解决方法是：人工解决。

**本地事务表**

另外一种实现，并不是所有的mq都支持事务消息。也就是消息一旦发送到消息队列中，消费者立马就可以消费到。

此时可以使用独立消息服务、或者本地事务表

<img src="https://img-blog.csdnimg.cn/daf08d40df934aeba8fd66983da846ae.png" style="zoom:50%;" />

可以看到，其实就是将消息先发送到一个我们自己编写的一个独立消息服务应用中，刚开始处于prepare状态，业务逻辑处理成功后，确认发送消息，这个时候独立消息服务才会真正的把消息发送给消息队列。

消费者消费成功后，ack时，除了对消息队列进行ack，对于独立消息服务也要进行ack，独立消息服务一般是把这条消息删除。

而定时扫描prepare状态的消息，向消息发送端(生产者)确认的工作也由独立消息服务来完成。

对于本地事务表，其实和独立消息服务的作用类似，只不过独立消息服务是需要独立部署的，而本地事务表是将独立消息服务的功能内嵌到应用中

**记住两点**

服务A和服务B，如果是同步调用，要求一起成功，或者一起失败，那么此时应选用TCC的事务框架

服务A和服务B，如果是异步调用，比如服务C先调用服务A后，服务C不用管服务B的执行结果，直接返回，那么这种情况下，应选用消息队列！

**场景案例**

很常见的一个异步调用场景:

- 支付宝往余额宝转钱

即将服务A假设为支付宝，服务B假设为余额宝

<img src="https://img-blog.csdnimg.cn/ac4478c689a84738abb2771e8c3b19e8.png" style="zoom:50%;" />

**一致性解决**

* 事务开始

* 给支付宝账户zhangsan,扣100元

* 将(给余额宝账户zhangsan,加100元)封装为消息，发送给消息队列

* 事务结束

如何保证第一步和第二步是在同一个事务里完成的。

换句话说，第一步操作的是数据库，第二步操作的是一个消息队列，你如何保证这两步之间的一致性？

记住了，任何涉及到数据库和中间件之间的业务逻辑操作，都需要考虑二者之间的一致性。

比如，你先操作了数据库，再操作缓存，数据库和缓存之间一致性如何解决？

改变思路，加一张事务表

事务的内容为：

* 事务开始

* 给支付宝账户zhangsan,扣100元

* 给事件表插入一条记录

* 事务结束

此时是对同一数据库的两张表操作，因此可以用数据库的事务进行保证。

另外，起一个定时程序，定时扫描事务表，发现一个状态为'UNFINISHED'的事件，就进行封装为消息，发送到消息中间件，然后将状态改为'FINISHED'

**幂等性解决**

仔细看，定时程序做了如下三个操作

* 定时扫描事务表，发现一个状态为'UNFINISHED'的事件

* 将事件信息，封装为消息，发送到消息中间件

* 将事件状态改为'FINISHED'

假设在步骤(2)的时候，发送完消息体，还未执行步骤(3),定时程序阵亡了！然后重启定时程序，发现刚那个事务的状态依然为'UNFINISHED'，因此重新发送。这样，就会出现重复消费问题。因此，幂等性也是需要保证的！

在消费者端，也维护一个带主键的表，可以选txid为主键

如果一旦出现重复消费，则在事务里直接报出主键冲突错误，从而保证了幂等性！

# 二阶段提交2PC

二阶段提交的底层实现主要分成两个阶段，分别是询问阶段和提交阶段。

所有节点都采用预写式日志，日志被写入后被保存在可靠的存储设备上，即使节点损坏也不会导致日志数据的丢失；

所有节点不会永久性损坏，即使损坏后仍然可以恢复。

**具体过程如下图所示：**

整个集群服务器被分成一台协调服务器，集群中的其他服务器是被协调的服务器。在二阶段算法的询问阶段，分布式集群服务在接收到来自客户端的请求的时候，首先会通过协调者服务器，针对本次请求能否正常执行向集群中参与处理的服务器发起询问请求。集群服务器在接收到请求的时候，会在本地机器上执行会话操作，并记录执行的相关日志信息，最后将结果返回给协调服务器。

<img src="https://img-blog.csdnimg.cn/f59dcc15b8864204ab8057ccce81a395.png" style="zoom:25%;" />

![](https://img-blog.csdnimg.cn/96ec6a6d933d4a84beb9a92292bc8ae7.png)

在协调服务器接收到来自集群中其他服务器的反馈信息后，会对信息进行统计。如果集群中的全部机器都能正确执行客户端发送的会话请求，那么协调者服务器就会再次向这些服务器发送提交命令。在集群服务器接收到协调服务器的提交指令后，会根据之前处理该条会话操作的日志记录在本地提交操作，并最终完成数据的修改。

**提交请求阶段**

在提交请求阶段，协调者将通知事务参与者准备提交事务，然后进入表决过程。在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地事务执行成功）或取消（本地事务执行故障），在第一阶段，参与节点并没有进行Commit操作。

**提交阶段**

在提交阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消这个事务。这个结果的处理和前面基于半数以上投票的一致性算法不同，必须当且仅当所有的参与者同意提交，协调者才会通知各个参与者提交事务，否则协调者将通知各个参与者取消事务。

参与者在接收到协调者发来的消息后将执行对应的操作，也就是本地 Commit 或者 Rollback。

虽然二阶段提交可以有效地保证客户端会话在分布式集群中的事务性，但是该算法自身也有很多问题，主要可以归纳为以下几点：效率问题、单点故障、异常中断。

![](https://img-blog.csdnimg.cn/1000c5388df2444eb7a975fcc7bd391a.png)

**资源被同步阻塞**

在数据提交的过程中，所有参与处理的服务器都处于阻塞状态，如果其他线程想访问临界区的资源，需要等待该条会话请求在本地执行完成后释放临界区资源。因此，采用二阶段提交算法也会降低程序并发执行的效率。

**单点问题**

此外，还会发生单点问题。单点问题也叫作单点服务器故障问题，它指的是当作为分布式集群系统的调度服务器发生故障时，整个集群因为缺少协调者而无法进行二阶段提交算法。单点问题也是二阶段提交最大的缺点，因此使用二阶段提交算法的时候通常都会进行一些改良，以满足对系统稳定性的要求。

**在 Commit 阶段出现数据不一致**

指的是当统计集群中的服务器可以进行事务操作时，协调服务器会向这些处理事务操作的服务器发送 commit 提交请求。如果在这个过程中，其中的一台或几台服务器发生网络故障，无法接收到来自协调服务器的提交请求，导致这些服务器无法完成最终的数据变更，就会造成整个分布式集群出现数据不一致的情况。

# 三阶段提交3PC

三阶段提交（Three-phase commit）简称 3PC ， 其实是在二阶段算法的基础上进行了优化和改进。

如下图所示，在整个三阶段提交的过程中，相比二阶段提交，增加了预提交阶段。

为了解决二阶段协议中的同步阻塞等问题，三阶段提交协议在协调者和参与者中都引入了超时机制，并且把两阶段提交协议的第一个阶段拆分成了两步：询问，然后再锁资源，最后真正提交。

![](https://img-blog.csdnimg.cn/cf111ac159534bff87bc148afb04c87f.png)



<img src="https://img-blog.csdnimg.cn/df8638caa5a24d78848c174c269c84c4.png" style="zoom:25%;" />

**预提交阶段**

为了保证事务性操作的稳定性，同时避免二阶段提交中因为网络原因造成数据不一致等问题，完成提交准备阶段后，集群中的服务器已经为请求操作做好了准备，协调服务器会向参与的服务器发送预提交请求。集群服务器在接收到预提交请求后，在本地执行事务操作，并将执行结果存储到本地事务日志中，并对该条事务日志进行锁定处理。

**提交阶段**

在处理完预提交阶段后，集群服务器会返回执行结果到协调服务器，最终，协调服务器会根据返回的结果来判断是否继续执行操作。如果所有参与者服务器返回的都是可以执行事务操作，协调者服务器就会再次发送提交请求到参与者服务器。参与者服务器在接收到来自协调者服务器的提交请求后，在本地正式提交该条事务操作，并在完成事务操作后关闭该条会话处理线程、释放系统资源。当参与者服务器执行完相关的操作时，会再次向协调服务器发送执行结果信息。

协调者服务器在接收到返回的状态信息后会进行处理，如果全部参与者服务器都正确执行，并返回 yes 等状态信息，整个事务性会话请求在服务端的操作就结束了。如果在接收到的信息中，有参与者服务器没有正确执行，则协调者服务器会再次向参与者服务器发送 rollback 回滚事务操作请求，整个集群就退回到之前的状态，这样就避免了数据不一致的问题。

为了保证数据的有一致性，我们引入了二阶段提交和三阶段提交算法。这两种算法都会将整个事务处理过程分成准备、执行、确认提交这几个阶段。不同的是，二阶段提交会因为网络原因造成数据不一致的问题，而三阶段提交通过增加预加载阶段将执行的事务数据保存到本地，当整个网络中的参与者服务器都能进行事务操作后，协调服务器会发送最终提交请求给参与者服务器，并最终完成事务操作的数据的修改。

**三阶段提交做了哪些改进**

> 引入超时机制

在 2PC 中，只有协调者拥有超时机制，如果在一定时间内没有收到参与者的消息则默认失败，3PC 同时在协调者和参与者中都引入超时机制。

> 添加预提交阶段

在 2PC 的准备阶段和提交阶段之间，插入一个准备阶段，使 3PC 拥有 CanCommit、PreCommit、DoCommit 三个阶段，PreCommit 是一个缓冲，保证了在最后提交阶段之前各参与节点的状态是一致的。

**三阶段提交协议存在的问题**

三阶段提交协议同样存在问题，具体表现为，在阶段三中，如果参与者接收到了 PreCommit 消息后，出现了不能与协调者正常通信的问题，在这种情况下，参与者依然会进行事务的提交，这就出现了数据的不一致性。

**两阶段和三阶段提交的应用**

两阶段提交是一种比较精简的一致性算法/协议，很多关系型数据库都是采用两阶段提交协议来完成分布式事务处理的，典型的比如 MySQL 的 XA 规范。

在事务处理、数据库和计算机网络中，两阶段提交协议提供了分布式设计中的数据一致性的保障，整个事务的参与者要么一致性全部提交成功，要么全部回滚。MySQL Cluster 内部数据的同步就是用的 2PC 协议。

> MySQL 的主从复制

在 MySQL 中，二进制日志是 server 层，主要用来做主从复制和即时点恢复时使用的；而事务日志（Redo Log）是 InnoDB 存储引擎层，用来保证事务安全的。

在数据库运行中，需要保证 Binlog 和 Redo Log 的一致性，如果顺序不一致， 则意味着 Master-Slave 可能不一致。

在开启 Binlog 后，如何保证 Binlog 和 InnoDB redo 日志的一致性呢？

MySQL 使用的就是二阶段提交，内部会自动将普通事务当做一个 XA 事务（内部分布式事务）来处理：

Commit 会被自动的分成 Prepare 和 Commit 两个阶段；

Binlog 会被当做事务协调者（Transaction Coordinator），Binlog Event 会被当做协调者日志。

# TCC

TCC的全称是（Try-Confirm-Cancel）

TCC 把事务运行过程分成 Try、Confirm / Cancel 两个阶段，每个阶段的逻辑由业务代码控制，避免了长事务，可以获取更高的性能。

TCC又可以被称为两阶段补偿事务，第一阶段try只是预留资源，第二阶段要明确的告诉服务提供者，这个资源你到底要不要，对应第二阶段的confirm/cancel，用来清除第一阶段的影响，所以叫补偿型事务。

<img src="https://img-blog.csdnimg.cn/a987f62cbcd44ef6a8621ee531f81fbf.png" style="zoom:50%;" />

比如，你的订单服务中本来只有一个接口

```java
//修改代码状态
orderClient.updateStatus()；
```

都要拆为三个接口，即

```java
orderClient.tryUpateStatus()；
orderClient.confirmUpateStatus()；
orderClient.cancelUpateStatus()；
```

**如果 Confirm 和 Cancel 阶段失败了怎么办？**

TCC 中会添加事务日志，如果 Confirm 或者 Cancel 阶段出错，则会进行重试，所以这两个阶段需要支持幂等；如果重试失败，则需要人工介入进行恢复和处理等。

**TCC有什么缺点？**

对代码入侵性大！每套业务逻辑、都要按try(请求资源)、confirm(操作资源)、cancel(取消资源)，拆分为三个接口！

**具体每个阶段，每个服务业务逻辑是什么样的呢?** 

假设，库存数量本来是50，那么可销售库存也是50。账户余额为50,可用余额也为50。用户下单，买了1个单价为1元的商品。

流程如下: 

* **Try阶段** 订单服务:修改订单的状态为**支付中** 账户服务:账户余额不变，可用余额减1，然后将1这个数字冻结在一个单独的字段里 库存服务:库存数量不变，可销售库存减1，然后将1这个数字冻结在一个单独的字段里 

* **confirm阶段** 订单服务:修改订单的状态为**支付完成** 账户服务:账户余额变为(当前值减冻结字段的值)，可用余额不变(Try阶段减过了),冻结字段清0。 库存服务:库存变为(当前值减冻结字段的值)，可销售库存不变(Try阶段减过了)，冻结字段清0。 

* **cancel阶段** 订单服务:修改订单的状态为**未支付** 账户服务:账户余额不变，可用余额变为(当前值加冻结字段的值)，冻结字段清0。 库存服务:库存不变，可销售库存变为(当前值加冻结字段的值)，冻结字段清0。

<img src="https://img-blog.csdnimg.cn/51c47058b16b4cf9b064bfa9230fad97.png" style="zoom:20%;" />

<img src="https://img-blog.csdnimg.cn/a140b136cf69400a9e412269c1eb28cc.png" style="zoom:50%;" />

**三方框架支持**

引入TCC分布式事务框架，事务的Try、Confirm、Cancel三个状态交给框架来感知！

你只要告诉框架，Try要执行啥，Confirm要执行啥，Cancel要执行啥!

如果Cancel过程出现异常了，框架有内部的补偿措施给你恢复数据！ 

以分布式tcc框架hmily为例，如果出现cancel异常或者confirm异常的情况，在try阶段会保存好日志，Hmily有内置的调度线程池来进行恢复，不用担心。 

**与 2PC/XA 两阶段提交的区别**

2PC/XA 是数据库或者存储资源层面的事务，实现的是强一致性，在两阶段提交的整个过程中，一直会持有数据库的锁。

TCC 关注业务层的正确提交和回滚，在 Try 阶段不涉及加锁，是业务层的分布式事务，关注最终一致性，不会一直持有各个业务资源的锁。

TCC 的核心思想是针对每个业务操作，都要添加一个与其对应的确认和补偿操作，同时把相关的处理，从数据库转移到业务中，以此实现跨数据库的事务。