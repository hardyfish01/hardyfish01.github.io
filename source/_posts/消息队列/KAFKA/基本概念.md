---
title: 基本概念
categories: 
- 消息队列
- KAFKA
---

<img src="https://img-blog.csdnimg.cn/3475507ccb3b407387a6d319fc42030a.png"/>

**主题**

发布订阅的对象是主题（`Topic`），可以为每 个业务、每个应用甚至是每类数据都创建专属的主题

**生产者和消费者**

向主题发布消息的客户端应用程序称为生产者，生产者程序通常持续不断地向一个或多个主题发送消息

订阅这些主题消息的客户端应用程序就被称为消费者，消费者也能够同时订阅多个主题的消息

**Broker**

集群由多个 Broker 组成，`Broker` 负责接收和处理客户端发送过来的请求，以及对消息进行持久化

虽然多个 Broker进程能够运行在同一台机器上，但更常见的做法是将不同的 `Broker` 分散运行在不同的机器上，这样如果集群中某一台机器宕机，即使在它上面 运行的所有Broker进程都挂掉了，其他机器上的 `Broker` 也依然能够对外提供服务

**备份机制**

备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本

> 定义了两类副本：领导者副本和追随者副本

前者对外提供服务，这里的对外指的是与 客户端程序进行交互；而后者只是被动地追随领导者副本而已，不能与外界进行交互

**分区**

分区机制指的是将每个主题划分成多个分区，每个分区是一组有序的消息日志

生产者生产的每条消息只会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，这条消息要么在分区 0 中，要么在分区 1 中

每个分区下可以配置若干个副本，其中只能有 1 个领 导者副本和 N-1 个追随者副本

生产者向分区写入消息，每条消息在分区中的位置信息叫位移

**消费者组**

多个消费者实例共同组成一个组来 消费一组主题

这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实例不能消费它

> 同时实现了传统消息引擎系统的两大模型：

如果所有实例都属于同一个 `Group`， 那么它实现的就是消息队列模型；

如果所有实例分别属于不 同的 `Group`，那么它实现的就是发布/订阅模型

**Coordinator：协调者**

所谓协调者，它专门为Consumer Group服务，负责为Group执行Rebalance以及提供位移管理和组成员管理等。

具体来讲，Consumer端应用程序在提交位移时，其实是向Coordinator所在的Broker提交位移，同样地，当Consumer应用启动时，也是向Coordinator所在的Broker发送各种请求，然后由Coordinator负责执行消费者组的注册、成员管理记录等元数据管理操作。

所有Broker在启动时，都会创建和开启相应的Coordinator组件。

也就是说，**所有Broker都有各自的Coordinator组件**。

Consumer Group如何确定为它服务的Coordinator在哪台Broker上呢？

通过Kafka内部主题`__consumer_offsets`。

目前，Kafka为某个Consumer Group确定Coordinator所在的Broker的算法有2个步骤。

* 第1步：确定由`__consumer_offsets`主题的哪个分区来保存该Group数据：`partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)`。

* 第2步：找出该分区Leader副本所在的Broker，该Broker即为对应的Coordinator。

首先，Kafka会计算该Group的`group.id`参数的哈希值。

比如你有个Group的`group.id`设置成了`test-group`，那么它的hashCode值就应该是627841412。

其次，Kafka会计算`__consumer_offsets`的分区数，通常是50个分区，之后将刚才那个哈希值对分区数进行取模加求绝对值计算，即`abs(627841412 % 50) = 12`。

此时，我们就知道了`__consumer_offsets`主题的分区12负责保存这个Group的数据。

有了分区号，我们只需要找出`__consumer_offsets`主题分区12的Leader副本在哪个Broker上就可以了，这个Broker，就是我们要找的Coordinator。

**消费者位移：Consumer Offset**

消费者消费进度，每个消费者都有自己的消费者位移。

**重平衡：Rebalance**

消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。

Rebalance是Kafka消费者端实现高可用的重要手段。

**AR（Assigned Replicas）**：分区中的所有副本统称为AR。

所有消息会先发送到leader副本，然后follower副本才能从leader中拉取消息进行同步。

但是在同步期间，follower对于leader而言会有一定程度的滞后，这个时候follower和leader并非完全同步状态

**OSR（Out Sync Replicas）**：follower副本与leader副本没有完全同步或滞后的副本集合

**ISR（In Sync Replicas）：**AR中的一个子集，ISR中的副本都**是与leader保持完全同步的副本**，如果某个在ISR中的follower副本落后于leader副本太多，则会被从ISR中移除，否则如果完全同步，会从OSR中移至ISR集合。

在默认情况下，当leader副本发生故障时，只有在ISR集合中的follower副本才有资格被选举为新leader，而OSR中的副本没有机会（可以通过`unclean.leader.election.enable`进行配置）

**HW（High Watermark）**：高水位，它标识了一个特定的消息偏移量（offset），消费者只能拉取到这个水位 offset 之前的消息

下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。

日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。

![](https://img-blog.csdnimg.cn/4e1db2420dbd48149811f55561bd2b01.png)

**LEO（Log End Offset）**：标识当前日志文件中下一条待写入的消息的offset

上图中offset为9的位置即为当前日志文件的 LEO，LEO 的大小相当于当前日志分区中最后一条消息的offset值加1

分区 ISR 集合中的每个副本都会维护自身的 LEO ，而 ISR 集合中最小的 LEO 即为分区的 HW，对消费者而言只能消费 HW 之前的消息。