---
title: 位移主题
categories: 
- 消息队列
- KAFKA
---

**Kafka将Consumer的位移数据作为一条条普通的Kafka消息，提交到__consumer_offsets中。**

* **__consumer_offsets的主要作用是保存Kafka消费者的位移信息。**

它要求这个提交过程不仅要实现高持久性，还要支持高频的写操作。

`__consumer_offsets`主题就是普通的Kafka主题。你可以手动地创建它、修改它，甚至是删除它。

Kafka Consumer有API帮你提交位移，也就是向`__consumer_offsets`主题写消息，千万不要自己写个Producer随意向该主题发送消息。

`__consumer_offsets`有3种消息格式：

1. 用于保存Consumer Group信息的消息。
2. 用于删除Group过期位移甚至是删除Group的消息。
3. 保存了位移值。

第2种格式它有个专属的名字：tombstone消息，即墓碑消息，也称delete mark，它的主要特点是它的消息体是null，即空消息体。

一旦某个Consumer Group下的所有Consumer实例都停止了，而且它们的位移数据都已被删除时，Kafka会向`__consumer_offsets`主题的对应分区写入tombstone消息，表明要彻底删除这个Group的信息。

`__consumer_offsets`是怎么被创建的？

* 通常来说，**当Kafka集群中的第一个Consumer程序启动时，Kafka会自动创建位移主题**。

**默认该主题的分区数是50，副本数是3**。

目前Kafka Consumer提交位移的方式有两种：**自动提交位移和手动提交位移。**

Consumer端有个参数叫`enable.auto.commit`，如果值是true，则Consumer在后台默默地为你定期提交位移，提交间隔由一个专属的参数`auto.commit.interval.ms`来控制。

* 自动提交位移有一个显著的优点，就是省事，你不用操心位移提交的事情，就能保证消息消费不会丢失。

但这一点同时也是缺点，丧失了很大的灵活性和可控性，你完全没法把控Consumer端的位移管理。

Kafka Consumer API为你提供了位移提交的方法，如`consumer.commitSync`等。

* 当调用这些方法时，Kafka会向`__consumer_offsets`主题写入相应的消息。

如果你选择的是自动提交位移，那么就可能存在一个问题：只要Consumer一直启动着，它就会无限期地向位移主题写入消息。

**举个极端一点的例子。**

假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。

* 由于是自动提交位移，位移主题中会不停地写入位移=100的消息。

显然Kafka只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。

这就要求Kafka必须要有针对位移主题消息特点的消息删除策略，否则这种消息会越来越多，最终撑爆整个磁盘。

**Compact策略**

Kafka使用**Compact策略**来删除`__consumer_offsets`主题中的过期消息，避免该主题无限期膨胀。

* 比如对于同一个Key的两条消息M1和M2，如果M1的发送时间早于M2，那么M1就是过期消息。

Compact的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起。

这里贴一张来自官网的图片，来说明Compact过程。

<img src="https://img-blog.csdnimg.cn/531c59bd687048ce9a3c269edc7a49d8.png"/>

图中位移为0、2和3的消息的Key都是K1，Compact之后，分区只需要保存位移为3的消息，因为它是最新发送的。

**Kafka提供了专门的后台线程定期地巡检待Compact的主题，看看是否存在满足条件的可删除数据**。

* 这个后台线程叫Log Cleaner。

很多实际生产环境中都出现过位移主题无限膨胀占用过多磁盘空间的问题，如果你的环境中也有这个问题，建议你去检查一下Log Cleaner线程的状态，通常都是这个线程挂掉了导致的。