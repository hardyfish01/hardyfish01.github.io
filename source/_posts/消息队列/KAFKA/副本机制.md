---
title: 副本机制
categories: 
- 消息队列
- KAFKA
---

同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的Broker上，从而能够对抗部分Broker宕机带来的数据不可用。

**下面展示的是一个有3台Broker的Kafka集群上的副本分布情况。**

主题1分区0的3个副本分散在3台Broker上，其他主题分区的副本也都散落在不同的Broker上，从而实现数据冗余。

<img src="https://img-blog.csdnimg.cn/db19af900d6a4c57bc8e699ff0686fbd.png" />

**副本角色**

<img src="https://img-blog.csdnimg.cn/c79146180b444a0d9277365f0f4e47f6.png">

在Kafka中，副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。

每个分区在创建时都要选举一个副本，称为领导者副本，其余的副本自动称为追随者副本。

> 在Kafka中，追随者副本是不对外提供服务的。

* 任何一个追随者副本都不能响应消费者和生产者的读写请求。

* 所有的请求都必须由领导者副本来处理，或者说，所有的读写请求都必须发往领导者副本所在的Broker，由该Broker负责处理。

追随者副本不处理客户端请求，它唯一的任务就是从领导者副本**异步拉取**消息，并写入到自己的提交日志中，从而实现与领导者副本的同步。

当领导者副本挂掉了，或者说领导者副本所在的Broker宕机时，Kafka依托于ZooKeeper提供的监控功能能够实时感知到，并立即开启新一轮的领导者选举，从追随者副本中选一个作为新的领导者。老Leader副本重启回来后，只能作为追随者副本加入到集群中。

**对于客户端用户而言，Kafka的追随者副本没有任何作用，Kafka为什么要这样设计呢？**

这种副本机制有两个方面的好处。

1.**方便实现Read-your-writes**。

所谓Read-your-writes，顾名思义就是，当你使用生产者API向Kafka成功写入消息后，马上使用消费者API去读取刚才生产的消息。

2.**方便实现单调读（Monotonic Reads）**。

假设当前有2个追随者副本F1和F2，它们异步地拉取领导者副本数据。

倘若F1拉取了Leader的最新消息而F2还未及时拉取，那么，此时如果有一个消费者先从F1读取消息之后又从F2拉取消息，它可能会看到这样的现象：第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性。

如果所有的读请求都是由Leader来处理，那么Kafka就很容易实现单调读一致性。

**leader 与 follower 的同步流程**

假设一个 topic，只要一个分区，有3个副本（1个leader， 2个follower），ISR中也是这3个副本，目前 topic 是空的，3个副本的 LEO 和 HW 的值都是 **0**。

现在 producer 向 leader 副本发送了一条消息，消息的整个同步流程：

* leader 接收到消息，把自己的 LEO 值更新为 1。

* 2个 follower 各自发请求给 leader。

* leader 把消息推送给 follower。

* follower 接收到消息后，更新自己的 LEO 为 1。

* leader 接收到 follower 的响应之后，HW 值更新为 1，此时 offset 为 0 的这条消息可以被 consumer 消费了。

对于设置了 `acks=-1` 的 producer，只有这5步都完成了，producer 才能正常返回，标志着这条消息发送成功。

# ISR机制

In-sync Replicas，也就是所谓的ISR副本集合。

ISR中的副本都是与Leader同步的副本，相反，不在ISR中的追随者副本就被认为是与Leader不同步的。

> 什么副本能够进入到ISR中呢？

Leader副本天然就在ISR中。

也就是说，**ISR不只是追随者副本集合，它必然包括Leader副本。甚至在某些情况下，ISR只有Leader这一个副本**。

另外，能够进入到ISR的追随者副本要满足一定的条件。

**通过Broker端参数replica.lag.time.max.ms参数值**。

这个参数的含义是Follower副本能够落后Leader副本的最长时间间隔，当前默认值是10秒。

这就是说，只要一个Follower副本落后Leader副本的时间不连续超过10秒，那么Kafka就认为该Follower副本与Leader是同步的，即使此时Follower副本中保存的消息明显少于Leader副本中的消息。

> Follower副本唯一的工作就是不断地从Leader副本拉取消息，然后写入到自己的提交日志中。

倘若该副本后面慢慢地追上了Leader的进度，那么它是能够重新被加回ISR的。

ISR是一个动态调整的集合，而非静态不变的。

# Unclean领导者选举

**Kafka把所有不在ISR中的存活副本都称为非同步副本**。

通常来说，非同步副本落后Leader太多，因此，如果选择这些副本作为新Leader，就可能出现数据的丢失。

毕竟，这些副本中保存的消息远远落后于老Leader中的消息。

在Kafka中，选举这种副本的过程称为Unclean领导者选举。

**Broker端参数unclean.leader.election.enable控制是否允许Unclean领导者选举**。

* 开启Unclean领导者选举可能会造成数据丢失，但好处是，它使得分区Leader副本一直存在，不至于停止对外提供服务，因此提升了高可用性。

* 反之，禁止Unclean领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性。

# 副本选举

对于kafka集群会尽量分配每一个partition的副本leader在不同的broker中，这样会避免多个leader在同一个broker，导致集群中的broker负载不平衡

**kafka引入了优先副本（preferred replica）的概念：**

* 优先副本的意思在AR（分区中的所有副本）集合列表中的第一个副本，在理想状态下该副本就是该分区的leader副本

例如kafka集群由3台broker组成，创建了一个名为`topic-partitions`的topic，设置partition为3，副本数为3，partition0中AR列表为 `[1,2,0]`，那么分区0的优先副本为1

> kafka使用多副本机制提高可靠性，但是只有leader副本对外提供读写服务，follow副本只是做消息同步。

**如果一个分区的leader副本不可用，就意味着整个分区不可用，此时需要从follower副本中选举出新的leader副本提供服务**。

**在创建主题的时候，该分区的主题和副本会尽可能的均匀发布到kafka的各个broker上**。

比如我们在包含3个broker节点的kafka集群上创建一个分区数为3，副本因子为3的主题`topic-partitions`时，leader副本会均匀的分布在3台broker节点上。

![](https://img-blog.csdnimg.cn/14ae99f3f10a4a02a296156f3b755a47.png)

**针对同一个分区，在同一个broker节点上不可能出现它的多个副本**。

我们可以把leader副本所在的节点叫作分区的leader节点，把follower副本所在的节点叫作follower节点。

在上面的例子中，分区0的leader节点是broker1，分区1的leader节点是broker2，分区2的leader节点是broker0。

* 当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。

* 当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。

* 比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。

当broker2重新恢复时，此时的kafka集群状态如下：

![](https://img-blog.csdnimg.cn/88e1662c4cca4976b6c6babeccce6d9d.png)

可以看到，此时broker1上负载更大，而broker2上没有负载。

**为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本**。

* 比如上面的分区1，它的AR集合是`[2,0,1]`，表示分区1的优先副本就是在broker2上。

理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。

**优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本**，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。

> kafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。

# LEO更新

LEO：last end offset，日志末端偏移量，记录了该副本对象底层日志文件中下一条消息的位移值。

> 举一个例子，若LEO=10，那么表示在该副本日志上已经保存了10条消息，位移范围是[0，9]

**follower更新LEO的机制**

follower副本的LEO保存在2个地方：

* follower副本所在的broker缓存里

* leader所在broker的缓存里，也就是leader所在broker的缓存上保存了该分区所有副本的LEO

**LEO何时更新呢？**

* 在follower发送FETCH请求后，leader将数据返回给follower，此时follower开始向底层log写数据，从而自动更新其LEO值，每当新写入一条消息，其LEO值就会加1。

* 在leader处理follower FETCH请求时。一旦leader接收到follower发送的FETCH请求，它首先会从自己的log中读取相应的数据，但是在给follower返回数据之前它先去更新follower的LEO。

**leader更新LEO机制**

leader的LEO就保存在其所在broker的缓存里，leader写log时就自动更新其LEO值。

# HW更新

follower更新HW发生在其更新LEO之后，一旦follower向log写完数据，它就会尝试更新HW值。

> 具体算法就是比较当前LEO值与FETCH响应中leader的HW值，取两者的小者作为新的HW值。

**leader更新HW的机制**

leader更新HW的时机：

1. producer 向 leader 写消息时
2. leader 处理 follower 的 fetch 请求时
3. 某副本成为leader时
4. broker 崩溃导致副本被踢出ISR时

**leader更新HW的方式：**

当尝试确定分区HW时，它会选出所有满足条件的副本，比较它们的LEO（当然包括leader自己的LEO），选择最小的LEO值作为HW值。

这里的满足条件主要是指副本要满足以下两个条件之一：

1. 处于ISR中
2. 副本LEO落后于leader LEO的时长不大于`replica.lag.time.max.ms`参数值（默认值是10秒）